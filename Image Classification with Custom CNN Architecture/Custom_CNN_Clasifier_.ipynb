{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "O9QGGaiABypf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHT30svK4ZOz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data\n",
        "- Load the dataset using your own custom code"
      ],
      "metadata": {
        "id": "QxF38jnECGPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Replace 'file_name.zip' with the name of your zip file\n",
        "zip_file_path = '/content/drive/MyDrive/CS6910/Assignment2/ImageClassification/team_16.zip'\n",
        "\n",
        "extract_to_path = '/content/dataset/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "# Normalize the image data to have mean 0 and standard deviation 1\n",
        "# Resize the image to 224x224\n",
        "# Convert the image to tensor\n",
        "# Create a DataLoader for the dataset\n",
        "# Use a batch size of 32\n",
        "# Shuffle the dataset\n",
        "\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root='./dataset/team_16/train', transform=data_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_dataset = datasets.ImageFolder(root='./dataset/team_16/test', transform=data_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "nnPK-w1fA_pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing normalized images"
      ],
      "metadata": {
        "id": "BTeXE_dvCI6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(train_loader.dataset[1000][0].permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c84IDRycBJIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions\n"
      ],
      "metadata": {
        "id": "sy2cCQjOCOrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageClassification:\n",
        "    def __init__(self, model, criterion, optimizer, deep_cnn='vgg'):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.deep_cnn = deep_cnn\n",
        "        self.train_losses = []\n",
        "        self.train_accuracies = []\n",
        "\n",
        "\n",
        "    def train(self, train_loader, num_epochs=5):\n",
        "        for epoch in range(num_epochs):\n",
        "            tqdm_train_loader = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
        "            self.model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for i, (images, labels) in enumerate(tqdm_train_loader):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "                predicted = torch.argmax(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                tqdm_train_loader.set_postfix({'Running Loss': running_loss / (i + 1)})\n",
        "                tqdm_train_loader.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "            train_loss = running_loss / len(train_loader)\n",
        "            train_accuracy = correct / total\n",
        "\n",
        "            self.train_losses.append(train_loss)\n",
        "            self.train_accuracies.append(train_accuracy)\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "\n",
        "            # save for each epoch\n",
        "            self.save_model(f'models/Q1/{self.deep_cnn}_epoch_{epoch+1}.pth')\n",
        "            # if train_loss < 0.01:\n",
        "            #     print('Loss is less than 0.01, stopping training')\n",
        "            #     # save the final model\n",
        "            #     self.save_model(f'models/Q1/{self.deep_cnn}_final.pth')\n",
        "            #     break\n",
        "\n",
        "    def evaluate(self, test_loader):\n",
        "        self.model.eval()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        test_accuracy = correct / total\n",
        "        test_loss = running_loss / len(test_loader)\n",
        "        return test_loss, test_accuracy\n",
        "\n",
        "    def test(self, test_loader):\n",
        "        test_loss, test_accuracy = self.evaluate(test_loader)\n",
        "        print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "    def plot_cm_train(self, train_loader):\n",
        "        self.model.eval()\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = self.model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        annot_labels = np.array([[f'{norm*100:.2f}%' for norm in row] for row in cm_norm])\n",
        "        sns.heatmap(cm, annot=annot_labels, fmt='', xticklabels=train_loader.dataset.classes, yticklabels=train_loader.dataset.classes, cmap='YlGnBu')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix (Train)')\n",
        "        plt.savefig(f'plots/confusion_matrix_train_{self.deep_cnn}.pdf', format='pdf', bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_cm_test(self, test_loader):\n",
        "        self.model.eval()\n",
        "        y_true = []\n",
        "        y_pred = []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = self.model(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                y_true.extend(labels.cpu().numpy())\n",
        "                y_pred.extend(predicted.cpu().numpy())\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        annot_labels = np.array([[f'{norm*100:.2f}%' for norm in row] for row in cm_norm])\n",
        "        sns.heatmap(cm, annot=annot_labels, fmt='', xticklabels=test_loader.dataset.classes, yticklabels=test_loader.dataset.classes, cmap='YlGnBu')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('True')\n",
        "        plt.title('Confusion Matrix (Test)')\n",
        "        plt.savefig(f'plots/confusion_matrix_test_{self.deep_cnn}.pdf', format='pdf', bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_losses(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(self.train_losses, label='Train Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "        plt.title('Train Loss')\n",
        "        plt.savefig(f'plots/losses_{self.deep_cnn}.pdf', format='pdf', bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_accuracies(self):\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(self.train_accuracies, label='Train Accuracy')\n",
        "\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.title('Train Accuracy')\n",
        "        plt.savefig(f'plots/accuracies_{self.deep_cnn}.pdf', format='pdf', bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "\n",
        "    def load_model(self, path):\n",
        "        self.model.load_state_dict(torch.load(path))\n",
        "\n"
      ],
      "metadata": {
        "id": "AqbhRQrEBObt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom CNN Definition, Training and Evaluation"
      ],
      "metadata": {
        "id": "ApLvbyCxEUqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc = nn.Linear(in_features=8 * 56 * 56, out_features=num_classes)  # Adjust 56 according to your image size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(torch.relu(self.conv1(x)))\n",
        "        x = self.pool2(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # All dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num_classes = len(train_dataset.classes) # = 5\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = CNN( num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "image_classification = ImageClassification(model, criterion, optimizer)\n",
        "image_classification.train(train_loader, num_epochs=10)\n",
        "image_classification.test(test_loader)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot confusion matrix, losses, and accuracies\n",
        "image_classification.plot_cm_train(train_loader)\n",
        "image_classification.plot_cm_test(test_loader)\n",
        "image_classification.plot_losses()\n",
        "image_classification.plot_accuracies()\n"
      ],
      "metadata": {
        "id": "vZqe_edhEDqH"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}