{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "fF_syoJuP_-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "!pip install emoji\n",
        "\n",
        "import re\n",
        "import emoji\n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())"
      ],
      "metadata": {
        "id": "VwpCnaQTG3fj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "YbL_2p_dQCLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cleaner(tweet):\n",
        "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
        "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
        "    tweet = \" \".join(tweet.split())\n",
        "    tweet = ''.join(c for c in tweet if not emoji.is_emoji(c)) #Remove Emojis\n",
        "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
        "    tweet = \" \".join(w for w in nltk.wordpunct_tokenize(tweet) \\\n",
        "         if w.lower() in words)\n",
        "    return tweet\n",
        "\n",
        "\n",
        "train_df = pd.read_csv(\"train (1).csv\")\n",
        "test_df = pd.read_csv(\"test (1).csv\")\n",
        "\n",
        "\n",
        "train_df['tweet'] = train_df['tweet'].map(lambda x: cleaner(x))\n",
        "test_df['tweet'] = test_df['tweet'].map(lambda x: cleaner(x))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_df['tokens'] = train_df['tweet'].apply(lambda x: x.split())\n",
        "test_df['tokens'] = test_df['tweet'].apply(lambda x: x.split())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_df['label'] = train_df['sentiment'].map({'Negative': 0, 'Positive': 1})\n",
        "test_df['label'] = test_df['sentiment'].map({'Negative': 0, 'Positive': 1})\n"
      ],
      "metadata": {
        "id": "qF6AVYuiHJVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GloVe Embedding setup"
      ],
      "metadata": {
        "id": "1cuNoLAjQLeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_path = \"glove.6B.200d.txt\"\n",
        "\n",
        "glove_embeddings = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split()\n",
        "        word = parts[0]\n",
        "        vector = torch.tensor([float(val) for val in parts[1:]], dtype=torch.float)\n",
        "        glove_embeddings[word] = vector\n",
        "\n",
        "\n",
        "# Create vocab from training tokens only\n",
        "vocab = {'<PAD>': 0, '<UNK>': 1}\n",
        "for token in set(t for tokens in train_df['tokens'] for t in tokens):\n",
        "    if token in glove_embeddings:\n",
        "        vocab[token] = len(vocab)\n",
        "\n",
        "embedding_matrix = torch.zeros(len(vocab), 200)\n",
        "embedding_matrix[1] = torch.randn(200)  # For UNK\n",
        "for word, idx in vocab.items():\n",
        "    if word in glove_embeddings:\n",
        "        embedding_matrix[idx] = glove_embeddings[word]"
      ],
      "metadata": {
        "id": "2qZIwdIjHp6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation"
      ],
      "metadata": {
        "id": "sdpn4f7yQUXN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TweetDataset(Dataset):\n",
        "    def __init__(self, tokens, labels=None):\n",
        "        self.sequences = [torch.tensor([vocab.get(t, 1) for t in tok], dtype=torch.long) for tok in tokens]\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32) if labels is not None else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.labels is not None:\n",
        "            return self.sequences[idx], self.labels[idx]\n",
        "        return self.sequences[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    if isinstance(batch[0], tuple):\n",
        "        sequences, labels = zip(*batch)\n",
        "        # Manually pad sequences\n",
        "        max_len = max(len(seq) for seq in sequences)\n",
        "        padded = []\n",
        "        for seq in sequences:\n",
        "            padded_seq = torch.cat([seq, torch.zeros(max_len - len(seq), dtype=torch.long)])\n",
        "            padded.append(padded_seq)\n",
        "        padded = torch.stack(padded).t()  # shape: (seq_len, batch)\n",
        "        return padded, torch.tensor(labels)\n",
        "    else:\n",
        "        max_len = max(len(seq) for seq in batch)\n",
        "        padded = []\n",
        "        for seq in batch:\n",
        "            padded_seq = torch.cat([seq, torch.zeros(max_len - len(seq), dtype=torch.long)])\n",
        "            padded.append(padded_seq)\n",
        "        padded = torch.stack(padded).t()\n",
        "        return padded\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = TweetDataset(train_df['tokens'], train_df['label'])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataset = TweetDataset(test_df['tokens'], test_df['label'])\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "5MpG9Cr1HyQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definition, Training and Evaluation"
      ],
      "metadata": {
        "id": "vj91aMqlQovq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_size=25):\n",
        "        super(RNNModel, self).__init__()\n",
        "        vocab_size, embed_dim = embedding_matrix.shape\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_size)  # batch_first=False is default\n",
        "        self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # (seq_len, batch, embed_dim)\n",
        "        out, _ = self.rnn(x)\n",
        "        return self.fc(out[-1]).squeeze(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RNNModel(embedding_matrix).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_train, total_train = 0, 0\n",
        "\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).long().squeeze()\n",
        "        correct_train += (preds == batch_y).sum().item()\n",
        "        total_train += batch_y.size(0)\n",
        "\n",
        "    train_acc = 100 * correct_train / total_train\n",
        "    train_losses.append(total_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    # --- Evaluation on Test Set ---\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).long().squeeze()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(all_labels, all_preds) * 100\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # Optional: F1, Precision, Recall per epoch (print or store)\n",
        "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    print(f\"Epoch {epoch}, Loss: {total_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%, F1: {f1:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot Train Loss and Accuracy\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.title(\"Train Loss per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_accuracies, label=\"Train Acc\")\n",
        "plt.plot(test_accuracies, label=\"Test Acc\")\n",
        "plt.title(\"Accuracy per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2NiadfG3IDrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Biased Data -> Unbiased Data"
      ],
      "metadata": {
        "id": "HdEtz5TYQtcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neg_df = train_df[train_df['label'] == 0]  # assuming 0 = Negative\n",
        "pos_df = train_df[train_df['label'] == 1]  # assuming 1 = Positive\n",
        "\n",
        "# Undersample the Negative class to match the size of the Positive class\n",
        "neg_df_sampled = neg_df.sample(n=len(pos_df), random_state=42)\n",
        "\n",
        "# Combine to get a balanced dataset\n",
        "balanced_train_df = pd.concat([pos_df, neg_df_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "neg_df = test_df[test_df['label'] == 0]  # assuming 0 = Negative\n",
        "pos_df = test_df[test_df['label'] == 1]  # assuming 1 = Positive\n",
        "\n",
        "# Undersample the Negative class to match the size of the Positive class\n",
        "neg_df_sampled = neg_df.sample(n=len(pos_df), random_state=42)\n",
        "\n",
        "# Combine to get a balanced dataset\n",
        "balanced_test_df = pd.concat([pos_df, neg_df_sampled]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "train_dataset = TweetDataset(balanced_train_df['tokens'], balanced_train_df['label'])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataset = TweetDataset(balanced_test_df['tokens'], balanced_test_df['label'])\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = RNNModel(embedding_matrix).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "fsCtuUzJN7MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_train, total_train = 0, 0\n",
        "\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        preds = (torch.sigmoid(outputs) > 0.5).long().squeeze()\n",
        "        correct_train += (preds == batch_y).sum().item()\n",
        "        total_train += batch_y.size(0)\n",
        "\n",
        "    train_acc = 100 * correct_train / total_train\n",
        "    train_losses.append(total_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "\n",
        "    # --- Evaluation on Test Set ---\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch_x, batch_y in test_loader:\n",
        "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
        "            outputs = model(batch_x)\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).long().squeeze()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "    test_acc = accuracy_score(all_labels, all_preds) * 100\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "    # Optional: F1, Precision, Recall per epoch (print or store)\n",
        "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    print(f\"Epoch {epoch}, Loss: {total_loss:.4f}, Train Acc: {train_acc:.2f}%, Test Acc: {test_acc:.2f}%, F1: {f1:.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Plot Train Loss and Accuracy\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.title(\"Train Loss per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_accuracies, label=\"Train Acc\")\n",
        "plt.plot(test_accuracies, label=\"Test Acc\")\n",
        "plt.title(\"Accuracy per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "N1hs5AqgP8Q6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}